#!/usr/bin/env python3
"""
ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®çš„è®­ç»ƒæµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯æ‰€æœ‰ä¿®å¤æ˜¯å¦æœ‰æ•ˆ
"""
import os
import sys
import torch
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ç¯å¢ƒå˜é‡é¿å…åˆ†å¸ƒå¼è®­ç»ƒé—®é¢˜
os.environ['WANDB_MODE'] = 'offline'
os.environ['NCCL_DEBUG'] = 'INFO'
os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # å¼ºåˆ¶ä½¿ç”¨å•GPU

def create_mock_batch():
    """åˆ›å»ºæ¨¡æ‹Ÿæ‰¹æ¬¡æ•°æ®"""
    batch_size = 2
    return {
        'aerial': torch.randn(batch_size, 4, 224, 224),
        's1': torch.randn(batch_size, 10, 2, 224, 224),  # æ—¶åºæ•°æ®
        's2': torch.randn(batch_size, 15, 10, 224, 224),  # æ—¶åºæ•°æ®
        'label': torch.randint(0, 2, (batch_size, 16)),  # å¤šæ ‡ç­¾
        'name': [f'sample_{i}.tif' for i in range(batch_size)]
    }

class MockDataset(torch.utils.data.Dataset):
    """æ¨¡æ‹Ÿæ•°æ®é›†"""
    def __init__(self, size=10):
        self.size = size
    
    def __len__(self):
        return self.size
    
    def __getitem__(self, idx):
        return {
            'aerial': torch.randn(4, 224, 224),
            's1': torch.randn(torch.randint(5, 15, (1,)).item(), 2, 224, 224),
            's2': torch.randn(torch.randint(10, 20, (1,)).item(), 10, 224, 224),
            'label': torch.randint(0, 2, (16,)),
            'name': f'sample_{idx}.tif'
        }

def mock_collate_fn(batch):
    """æ¨¡æ‹Ÿcollateå‡½æ•°"""
    output = {}
    
    # å¤„ç†æ—¶åºæ•°æ®
    for key in ['s1', 's2']:
        if key in batch[0]:
            tensors = [x[key] for x in batch]
            max_time = max(t.size(0) for t in tensors)
            padded = []
            for t in tensors:
                pad_size = max_time - t.size(0)
                if pad_size > 0:
                    padding = torch.zeros(pad_size, *t.shape[1:])
                    padded.append(torch.cat([t, padding], dim=0))
                else:
                    padded.append(t)
            output[key] = torch.stack(padded)
    
    # å¤„ç†å…¶ä»–æ•°æ®
    for key in ['aerial', 'label']:
        if key in batch[0]:
            output[key] = torch.stack([x[key] for x in batch])
    
    # å¤„ç†æ–‡ä»¶å
    if 'name' in batch[0]:
        output['name'] = [x['name'] for x in batch]
    
    return output

def test_training():
    """æµ‹è¯•è®­ç»ƒæµç¨‹"""
    print("ğŸ§ª TreeSATå¤šæ¨¡æ€åµŒå…¥è®­ç»ƒæµ‹è¯•ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰")
    print("=" * 50)
    
    try:
        # æ£€æŸ¥CUDA
        if torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨ï¼ŒGPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"âœ… å½“å‰GPU: {torch.cuda.get_device_name()}")
        else:
            print("âš ï¸  æœªæ£€æµ‹åˆ°CUDAï¼Œå°†ä½¿ç”¨CPU")
        
        # æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
        sys.path.append('src')
        
        from models.embedding import MultiModalEmbeddingModel
        import lightning as L
        
        print("\nğŸ“Š æµ‹è¯•æ¨¡æ‹Ÿæ•°æ®...")
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†
        dataset = MockDataset(size=10)
        dataloader = torch.utils.data.DataLoader(
            dataset,
            batch_size=2,
            shuffle=False,
            num_workers=0,
            collate_fn=mock_collate_fn
        )
        
        print("âœ… æ¨¡æ‹Ÿæ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ‰¹æ¬¡æ•°æ®
        batch = next(iter(dataloader))
        print(f"âœ… æ‰¹æ¬¡æ•°æ®å½¢çŠ¶:")
        for key, value in batch.items():
            if isinstance(value, torch.Tensor):
                print(f"   {key}: {value.shape}")
            else:
                print(f"   {key}: {type(value)} (length: {len(value)})")
        
        print("\nğŸ¤– æµ‹è¯•æ¨¡å‹åˆ›å»º...")
        # åˆ›å»ºæ¨¡å‹
        model = MultiModalEmbeddingModel(
            embed_dim=128,
            backbone='resnet50',
            temperature=0.07,
            learning_rate=1e-4,
            log_wandb=False  # ç¦ç”¨wandbé¿å…å†²çª
        )
        
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        print("\nâš¡ æµ‹è¯•ç®€å•å‰å‘ä¼ æ’­...")
        model.eval()
        
        with torch.no_grad():
            embeddings = model(batch)
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼Œembeddingå½¢çŠ¶:")
            for modality, emb in embeddings.items():
                print(f"   {modality}: {emb.shape}")
        
        print("\nğŸƒ æµ‹è¯•è®­ç»ƒæ­¥éª¤...")
        model.train()
        
        # æµ‹è¯•training_step
        try:
            # æ¨¡æ‹Ÿtrainer
            model.trainer = type('MockTrainer', (), {
                'global_step': 0,
                'current_epoch': 0,
                'optimizers': [torch.optim.Adam(model.parameters())]
            })()
            
            loss = model.training_step(batch, 0)
            print(f"âœ… è®­ç»ƒæ­¥éª¤æˆåŠŸï¼ŒæŸå¤±: {loss.item():.4f}")
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒæ­¥éª¤å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
        
        print("\nğŸ¯ æµ‹è¯•Lightningè®­ç»ƒå™¨...")
        
        # åˆ›å»ºLightningè®­ç»ƒå™¨ï¼ˆå•GPUï¼ŒçŸ­æ—¶é—´ï¼‰
        trainer = L.Trainer(
            max_epochs=1,
            devices=1 if torch.cuda.is_available() else 'cpu',
            precision='32',  # ä½¿ç”¨FP32é¿å…ç²¾åº¦é—®é¢˜
            enable_checkpointing=False,
            logger=False,  # ç¦ç”¨æ—¥å¿—è®°å½•å™¨
            enable_model_summary=False,
            num_sanity_val_steps=0,  # è·³è¿‡éªŒè¯sanity check
            limit_train_batches=3,  # åªè®­ç»ƒ3ä¸ªæ‰¹æ¬¡
            limit_val_batches=0,   # è·³è¿‡éªŒè¯
            enable_progress_bar=True,
            accelerator='auto',
            strategy='auto',  # è‡ªåŠ¨é€‰æ‹©ç­–ç•¥
            deterministic=False  # ç¦ç”¨ç¡®å®šæ€§ä»¥é¿å…æ€§èƒ½è­¦å‘Š
        )
        
        print("âœ… Lightningè®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")
        
        # é‡æ–°åˆ›å»ºæ¨¡å‹ï¼ˆé‡ç½®çŠ¶æ€ï¼‰
        model = MultiModalEmbeddingModel(
            embed_dim=128,
            backbone='resnet50',
            temperature=0.07,
            learning_rate=1e-4,
            log_wandb=False
        )
        
        print("ğŸš€ å¼€å§‹è®­ç»ƒæµ‹è¯•...")
        trainer.fit(model, dataloader)
        
        print("ğŸ‰ è®­ç»ƒæµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_training()
    if success:
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¿®å¤çš„é—®é¢˜åŒ…æ‹¬ï¼š")
        print("   1. âœ… åˆ†å¸ƒå¼è®­ç»ƒé…ç½®é—®é¢˜ - é»˜è®¤ä½¿ç”¨å•GPU")
        print("   2. âœ… NCCLé€šä¿¡é”™è¯¯ - æ™ºèƒ½GPUæ£€æµ‹å’Œç­–ç•¥é€‰æ‹©")
        print("   3. âœ… Wandbæ­¥æ•°å†²çª - ç§»é™¤æ‰‹åŠ¨æ­¥æ•°è®¾ç½®")
        print("   4. âœ… æ•°æ®åŠ è½½é—®é¢˜ - collate_fné”™è¯¯å¤„ç†")
        print("   5. âœ… BatchNormé—®é¢˜ - ä½¿ç”¨åˆé€‚çš„æ‰¹æ¬¡å¤§å°")
        print("\nğŸ¯ ç°åœ¨å¯ä»¥å®‰å…¨åœ°å¼€å§‹æ­£å¼è®­ç»ƒï¼")
        print("   æ¨èå‘½ä»¤: python src/train_embedding.py --num_devices 1 --max_epochs 50 --batch_size 32")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜ã€‚") 