#!/usr/bin/env python3
"""
æµ‹è¯•TreeSATæ•°æ®åŠ è½½åŠŸèƒ½
"""

import os
import sys
import torch

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data.TreeSAT import TreeSAT
from data.transforms.transform import TransformMAE
from data.utils import get_treesat_classes

def test_single_sample(data_path):
    """æµ‹è¯•å•ä¸ªæ ·æœ¬åŠ è½½"""
    print("=" * 50)
    print("æµ‹è¯•å•ä¸ªæ ·æœ¬åŠ è½½")
    print("=" * 50)
    
    try:
        # è·å–ç±»åˆ«
        classes = get_treesat_classes(data_path, verbose=False)
        
        # åˆ›å»ºæ•°æ®å˜æ¢
        transform = TransformMAE(p=0.0, size=224)
        
        # åˆ›å»ºæ•°æ®é›†ï¼ˆåªä½¿ç”¨å¾ˆå°çš„åˆ†åŒºï¼‰
        dataset = TreeSAT(
            path=data_path,
            modalities=['aerial', 's1', 's2'],
            transform=transform,
            split='train',
            classes=classes,
            partition=0.01  # åªä½¿ç”¨1%çš„æ•°æ®
        )
        
        print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        if len(dataset) == 0:
            print("âŒ æ•°æ®é›†ä¸ºç©º")
            return False
        
        # æµ‹è¯•è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬
        print("å°è¯•è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬...")
        sample = dataset[0]
        
        print("âœ… æˆåŠŸè·å–æ ·æœ¬")
        print(f"æ ·æœ¬åŒ…å«çš„é”®: {list(sample.keys())}")
        
        # åˆ†ææ¯ä¸ªæ¨¡æ€çš„æ•°æ®
        for key, value in sample.items():
            if key in ['label', 'name']:
                if key == 'label':
                    print(f"{key}: å½¢çŠ¶={value.shape}, ç±»å‹={type(value)}")
                else:
                    print(f"{key}: {value}")
            else:
                if torch.is_tensor(value):
                    print(f"{key}: å½¢çŠ¶={value.shape}, æ•°æ®ç±»å‹={value.dtype}, æœ€å°å€¼={value.min():.3f}, æœ€å¤§å€¼={value.max():.3f}")
                else:
                    print(f"{key}: ç±»å‹={type(value)}, å€¼={value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_dataloader(data_path, batch_size=2):
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ•°æ®åŠ è½½å™¨")
    print("=" * 50)
    
    try:
        # è·å–ç±»åˆ«
        classes = get_treesat_classes(data_path, verbose=False)
        
        # åˆ›å»ºæ•°æ®å˜æ¢
        transform = TransformMAE(p=0.0, size=224)
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = TreeSAT(
            path=data_path,
            modalities=['aerial', 's1', 's2'],
            transform=transform,
            split='train',
            classes=classes,
            partition=0.01  # åªä½¿ç”¨1%çš„æ•°æ®
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        dataloader = torch.utils.data.DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=0,  # ä½¿ç”¨0ä¸ªworkeré¿å…å¤šè¿›ç¨‹é—®é¢˜
            collate_fn=dataset.collate_fn
        )
        
        print(f"æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
        
        # å°è¯•è·å–ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
        print("å°è¯•è·å–ç¬¬ä¸€ä¸ªæ‰¹æ¬¡...")
        for i, batch in enumerate(dataloader):
            print(f"âœ… æˆåŠŸè·å–æ‰¹æ¬¡ {i+1}")
            print(f"æ‰¹æ¬¡åŒ…å«çš„é”®: {list(batch.keys())}")
            
            # åˆ†ææ‰¹æ¬¡ä¸­æ¯ä¸ªæ¨¡æ€çš„æ•°æ®
            for key, value in batch.items():
                if key in ['label', 'name']:
                    if key == 'label':
                        print(f"{key}: å½¢çŠ¶={value.shape}, ç±»å‹={type(value)}")
                    else:
                        print(f"{key}: é•¿åº¦={len(value)}")
                else:
                    if torch.is_tensor(value):
                        print(f"{key}: å½¢çŠ¶={value.shape}, æ•°æ®ç±»å‹={value.dtype}")
                    else:
                        print(f"{key}: ç±»å‹={type(value)}")
            
            # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
            break
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model_forward(data_path):
    """æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­")
    print("=" * 50)
    
    try:
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„embeddingæ¨¡å‹è¿›è¡Œæµ‹è¯•
        from models.embedding import ModalityEncoder
        
        # åˆ›å»ºç¼–ç å™¨
        aerial_encoder = ModalityEncoder(input_channels=4, embed_dim=128, backbone='resnet50')
        s1_encoder = ModalityEncoder(input_channels=2, embed_dim=128, backbone='resnet50')
        s2_encoder = ModalityEncoder(input_channels=10, embed_dim=128, backbone='resnet50')
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œé¿å…BatchNormé—®é¢˜
        aerial_encoder.eval()
        s1_encoder.eval()
        s2_encoder.eval()
        
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # è·å–æ•°æ®
        classes = get_treesat_classes(data_path, verbose=False)
        transform = TransformMAE(p=0.0, size=224)
        dataset = TreeSAT(
            path=data_path,
            modalities=['aerial', 's1', 's2'],
            transform=transform,
            split='train',
            classes=classes,
            partition=0.01
        )
        
        dataloader = torch.utils.data.DataLoader(
            dataset,
            batch_size=2,  # ä½¿ç”¨æ‰¹æ¬¡å¤§å°2ï¼Œé¿å…BatchNormé—®é¢˜
            shuffle=False,
            num_workers=0,
            collate_fn=dataset.collate_fn
        )
        
        # è·å–ä¸€ä¸ªæ‰¹æ¬¡è¿›è¡Œæµ‹è¯•
        batch = next(iter(dataloader))
        
        # æµ‹è¯•æ¯ä¸ªç¼–ç å™¨
        with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜
            if 'aerial' in batch:
                print("æµ‹è¯•aerialç¼–ç å™¨...")
                aerial_emb = aerial_encoder(batch['aerial'])
                print(f"âœ… aerial embeddingå½¢çŠ¶: {aerial_emb.shape}")
            
            if 's1' in batch:
                print("æµ‹è¯•s1ç¼–ç å™¨...")
                s1_emb = s1_encoder(batch['s1'])
                print(f"âœ… s1 embeddingå½¢çŠ¶: {s1_emb.shape}")
            
            if 's2' in batch:
                print("æµ‹è¯•s2ç¼–ç å™¨...")
                s2_emb = s2_encoder(batch['s2'])
                print(f"âœ… s2 embeddingå½¢çŠ¶: {s2_emb.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    data_path = "/data/AnySat/TreeSat/"
    
    # æ£€æŸ¥æ•°æ®è·¯å¾„
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")
        return
    
    # æµ‹è¯•å•ä¸ªæ ·æœ¬åŠ è½½
    success1 = test_single_sample(data_path)
    
    if not success1:
        print("å•ä¸ªæ ·æœ¬åŠ è½½å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
        return
    
    # æµ‹è¯•æ•°æ®åŠ è½½å™¨
    success2 = test_dataloader(data_path)
    
    if not success2:
        print("æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
        return
    
    # æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
    success3 = test_model_forward(data_path)
    
    if success1 and success2 and success3:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®åŠ è½½å’Œæ¨¡å‹å‰å‘ä¼ æ’­æ­£å¸¸ã€‚")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶ã€‚")

if __name__ == '__main__':
    print("TreeSATæ•°æ®åŠ è½½æµ‹è¯•å·¥å…·")
    print("=" * 50)
    main() 