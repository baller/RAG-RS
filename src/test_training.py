#!/usr/bin/env python3
"""
ç®€åŒ–çš„è®­ç»ƒæµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯æ‰€æœ‰ä¿®å¤æ˜¯å¦æœ‰æ•ˆ
"""
import os
import sys
import torch
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ç¯å¢ƒå˜é‡é¿å…åˆ†å¸ƒå¼è®­ç»ƒé—®é¢˜
os.environ['WANDB_MODE'] = 'offline'
os.environ['NCCL_DEBUG'] = 'INFO'
os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # å¼ºåˆ¶ä½¿ç”¨å•GPU

def test_training():
    """æµ‹è¯•è®­ç»ƒæµç¨‹"""
    print("ğŸ§ª TreeSATå¤šæ¨¡æ€åµŒå…¥è®­ç»ƒæµ‹è¯•")
    print("=" * 50)
    
    try:
        # æ£€æŸ¥CUDA
        if torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨ï¼ŒGPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"âœ… å½“å‰GPU: {torch.cuda.get_device_name()}")
        else:
            print("âš ï¸  æœªæ£€æµ‹åˆ°CUDAï¼Œå°†ä½¿ç”¨CPU")
        
        # æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
        sys.path.append('src')
        
        from data.utils import get_treesat_classes
        from data.transforms.transform import TransformMAE
        from data.TreeSAT import TreeSAT
        from models.embedding import MultiModalEmbeddingModel
        import lightning as L
        
        # æ•°æ®è·¯å¾„
        data_path = "/data/zhangguiwei/KAN4RSImg/TreeSatAI/TreeSatAI_v1_0_processed"
        
        print("\nğŸ“Š æµ‹è¯•æ•°æ®åŠ è½½...")
        classes = get_treesat_classes(data_path, verbose=False)
        print(f"âœ… åŠ è½½ç±»åˆ«æ•°: {len(classes)}")
        
        # åˆ›å»ºæ•°æ®é›†ï¼ˆä½¿ç”¨æœ€å°æ•°æ®é‡æµ‹è¯•ï¼‰
        transform = TransformMAE(p=0.0, size=224)
        dataset = TreeSAT(
            path=data_path,
            modalities=['aerial', 's1', 's2'],
            transform=transform,
            split='train',
            classes=classes,
            partition=0.01  # ä½¿ç”¨1%æ•°æ®è¿›è¡Œå¿«é€Ÿæµ‹è¯•
        )
        
        print(f"âœ… æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        dataloader = torch.utils.data.DataLoader(
            dataset,
            batch_size=2,
            shuffle=False,
            num_workers=0,  # ä½¿ç”¨0é¿å…å¤šè¿›ç¨‹é—®é¢˜
            collate_fn=dataset.collate_fn
        )
        
        print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        print("\nğŸ¤– æµ‹è¯•æ¨¡å‹åˆ›å»º...")
        # åˆ›å»ºæ¨¡å‹
        model = MultiModalEmbeddingModel(
            embed_dim=128,
            backbone='resnet50',
            temperature=0.07,
            learning_rate=1e-4,
            log_wandb=False  # ç¦ç”¨wandbé¿å…å†²çª
        )
        
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        print("\nâš¡ æµ‹è¯•ç®€å•å‰å‘ä¼ æ’­...")
        model.eval()
        batch = next(iter(dataloader))
        
        with torch.no_grad():
            embeddings = model(batch)
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼Œembeddingå½¢çŠ¶:")
            for modality, emb in embeddings.items():
                print(f"   {modality}: {emb.shape}")
        
        print("\nğŸƒ æµ‹è¯•è®­ç»ƒæ­¥éª¤...")
        model.train()
        
        # æµ‹è¯•training_step
        try:
            # æ¨¡æ‹Ÿtrainer
            model.trainer = type('MockTrainer', (), {
                'global_step': 0,
                'current_epoch': 0,
                'optimizers': [torch.optim.Adam(model.parameters())]
            })()
            
            loss = model.training_step(batch, 0)
            print(f"âœ… è®­ç»ƒæ­¥éª¤æˆåŠŸï¼ŒæŸå¤±: {loss.item():.4f}")
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒæ­¥éª¤å¤±è´¥: {e}")
            return False
        
        print("\nğŸ¯ æµ‹è¯•Lightningè®­ç»ƒå™¨...")
        
        # åˆ›å»ºLightningè®­ç»ƒå™¨ï¼ˆå•GPUï¼ŒçŸ­æ—¶é—´ï¼‰
        trainer = L.Trainer(
            max_epochs=1,
            devices=1 if torch.cuda.is_available() else 'cpu',
            precision='32',  # ä½¿ç”¨FP32é¿å…ç²¾åº¦é—®é¢˜
            enable_checkpointing=False,
            logger=False,  # ç¦ç”¨æ—¥å¿—è®°å½•å™¨
            enable_model_summary=False,
            num_sanity_val_steps=0,  # è·³è¿‡éªŒè¯sanity check
            limit_train_batches=2,  # åªè®­ç»ƒ2ä¸ªæ‰¹æ¬¡
            limit_val_batches=0,   # è·³è¿‡éªŒè¯
            enable_progress_bar=True,
            accelerator='auto',
            strategy='auto',  # è‡ªåŠ¨é€‰æ‹©ç­–ç•¥
            deterministic=False  # ç¦ç”¨ç¡®å®šæ€§ä»¥é¿å…æ€§èƒ½è­¦å‘Š
        )
        
        print("âœ… Lightningè®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")
        
        # é‡æ–°åˆ›å»ºæ¨¡å‹ï¼ˆé‡ç½®çŠ¶æ€ï¼‰
        model = MultiModalEmbeddingModel(
            embed_dim=128,
            backbone='resnet50',
            temperature=0.07,
            learning_rate=1e-4,
            log_wandb=False
        )
        
        print("ğŸš€ å¼€å§‹è®­ç»ƒæµ‹è¯•...")
        trainer.fit(model, dataloader)
        
        print("ğŸ‰ è®­ç»ƒæµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_training()
    if success:
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è®­ç»ƒæµç¨‹æ­£å¸¸å·¥ä½œã€‚")
        print("\nğŸ¯ å¯ä»¥å¼€å§‹æ­£å¼è®­ç»ƒï¼š")
        print("   python src/train_embedding.py --num_devices 1 --max_epochs 50")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜ã€‚") 